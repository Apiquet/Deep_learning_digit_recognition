{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "C:\\Users\\antho\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:43: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "C:\\Users\\antho\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\antho\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:48: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import dlc_practical_prologue      \n",
    "size=1000;\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = \\\n",
    "    dlc_practical_prologue.generate_pair_sets(size)\n",
    "train_input, train_target, train_classes = Variable(train_input), Variable(train_target), Variable((train_classes))\n",
    "test_input, test_target, test_classes = Variable(test_input), Variable(test_target), Variable(test_classes)\n",
    "mini_batch_size = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.imshow(test_input[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Value: {}\".format(test_classes[i][0]))  \n",
    "  plt.tight_layout()\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.imshow(test_input[i][1], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Value: {}\".format(test_classes[i][1]))  \n",
    "  plt.tight_layout()\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First neural net\n",
    "Train the model on all the 2000 images in train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_train_input1 = train_input[:,0,:]\n",
    "my_train_input2 = train_input[:,1,:]\n",
    "my_train_classes1 = train_classes[0:1000,0]\n",
    "my_train_classes2 = train_classes[0:1000,1]\n",
    "\n",
    "my_test_input1 = test_input[:,0,:]\n",
    "my_test_input2 = test_input[:,1,:]\n",
    "my_test_classes1 = test_classes[0:1000,0]\n",
    "my_test_classes2 = test_classes[0:1000,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# number of epoch\n",
    "num_epochs = 25\n",
    "# batch size to compute mini-batch\n",
    "batch_size = 2\n",
    "# number of pixels in the image \n",
    "input_size = 20\n",
    "# number of possible digit: 0 to 9 \n",
    "num_class = 2\n",
    "# small step to find a minima\n",
    "learning_rate = 0.001\n",
    "# hidden size\n",
    "hidden_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model_, my_test_input1_, my_test_input2_, test_target_, batch_size_):\n",
    "    total = 0\n",
    "    well_predicted_count = 0\n",
    "    for i in range(int(len(my_test_input1_)/batch_size_)):\n",
    "        images1 = my_test_input1_.narrow(0,i*batch_size_,batch_size_).to(device)\n",
    "        images2 = my_test_input2_.narrow(0,i*batch_size_,batch_size_).to(device)\n",
    "        labels = test_target_.narrow(0,i*batch_size_,batch_size_).to(device)\n",
    "        total += labels.size(0)\n",
    "        out1, out2, result = model_(images1, images2, batch_size_)\n",
    "        \n",
    "        t = Variable(torch.Tensor([0.5]))\n",
    "        predictions = (result > t).float() * 1\n",
    "        predictions = predictions.reshape(1000)\n",
    "        \n",
    "        well_predicted_count += (predictions.long() == labels).sum().item()\n",
    "\n",
    "    return 1 - well_predicted_count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "def train_model(model_, my_train_input1_, my_train_input2_, my_test_classes1, my_test_classes2, train_target_, criterion_, optimizer_,num_epochs_,batch_size_):\n",
    "\n",
    "    train_error = []\n",
    "    test_error = []\n",
    "    # train function\n",
    "    for epoch in range(1, num_epochs_+1):\n",
    "        for i in range(int(len(my_train_input1_)/batch_size_)):  \n",
    "            # Move tensors to the configured device\n",
    "            images1 = my_train_input1_.narrow(0,i*batch_size_,batch_size_).to(device)\n",
    "            images2 = my_train_input2_.narrow(0,i*batch_size_,batch_size_).to(device)\n",
    "            labels1 = my_test_classes1.narrow(0,i*batch_size_,batch_size_).to(device)\n",
    "            labels2 = my_test_classes2.narrow(0,i*batch_size_,batch_size_).to(device)\n",
    "            target_labels = train_target_.narrow(0,i*batch_size_,batch_size_).to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            out1, out2, result = model_(images1, images2, batch_size_)\n",
    "            #result.requires_grad=True\n",
    "            loss1 = criterion_(out1, labels1)\n",
    "            loss2 = criterion_(out2, labels2)\n",
    "            \n",
    "            \"\"\"_, predictions1 = torch.max(out1.data, 1)\n",
    "            _, predictions2 = torch.max(out2.data, 1)\n",
    "            predictions = (predictions1 >= predictions2).long()\"\"\"\n",
    "\n",
    "            criterion3 = nn.MSELoss()\n",
    "            loss3 = criterion3(result, train_target_.float())\n",
    "            real_loss = loss1 + loss2 + loss3\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer_.zero_grad()\n",
    "            real_loss.backward()\n",
    "            optimizer_.step()            \n",
    "\n",
    "\n",
    "        train_error.append(test_accuracy(model_, my_train_input1_, my_train_input2_, train_target,1000))\n",
    "        test_error.append(test_accuracy(model_, my_test_input1, my_test_input2, test_target,1000))\n",
    "        if(epoch % 5 == 0 or epoch == 1):    \n",
    "            print ('Loss: {:.4f} on epoch: {}, train error: {}, test error: {}'.format(real_loss.item(),epoch,train_error[-1],test_error[-1]))\n",
    "    return train_error, test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2634 on epoch: 1, train error: 0.5740000000000001, test error: 0.5569999999999999\n",
      "Loss: 0.4072 on epoch: 5, train error: 0.493, test error: 0.497\n",
      "Loss: 0.2497 on epoch: 10, train error: 0.501, test error: 0.52\n",
      "Loss: 0.3868 on epoch: 15, train error: 0.477, test error: 0.5\n",
      "Loss: 0.2592 on epoch: 20, train error: 0.472, test error: 0.46799999999999997\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-b913c670dd70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m \u001b[0mtrain_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmy_train_input1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmy_train_input2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmy_train_classes1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmy_train_classes2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-37-3a8fe5ef67c6>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model_, my_train_input1_, my_train_input2_, my_test_classes1, my_test_classes2, train_target_, criterion_, optimizer_, num_epochs_, batch_size_)\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;31m# Backward and optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0moptimizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mreal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             \u001b[0moptimizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#as we got 100% on the train error it seems that we just leared by heart the train dataset\n",
    "# let's adding regularization:\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_class):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=3))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=3))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(64, 25)\n",
    "        self.fc2 = nn.Linear(25, 10)\n",
    "        \n",
    "        self.layer1_comp = nn.Linear(input_size, 30)\n",
    "        self.relu = nn.Softmax()\n",
    "        self.layer2_comp = nn.Linear(30, 1)\n",
    "    \n",
    "    def forward(self, img1, img2, batch_size_images):\n",
    "        img1 = img1.reshape(batch_size_images,1,14,14)\n",
    "        out1 = self.layer1(img1)        \n",
    "        out1 = self.layer2(out1)\n",
    "        out1 = out1.reshape(out1.size(0), -1)\n",
    "        out1 = self.drop_out(out1)\n",
    "        out1 = self.fc1(out1)\n",
    "        out1 = self.fc2(out1)\n",
    "        \n",
    "        img2 = img2.reshape(batch_size_images,1,14,14)\n",
    "        out2 = self.layer1(img2)        \n",
    "        out2 = self.layer2(out2)\n",
    "        out2 = out2.reshape(out2.size(0), -1)\n",
    "        out2 = self.drop_out(out2)\n",
    "        out2 = self.fc1(out2)\n",
    "        out2 = self.fc2(out2)\n",
    "\n",
    "        result = torch.cat((out1, out2),1)\n",
    "\n",
    "        result = self.layer1_comp(result)\n",
    "        result = self.relu(result)\n",
    "        result = self.layer2_comp(result)\n",
    "        return out1, out2, result\n",
    "  \n",
    "# creating neural net\n",
    "model = NeuralNet(input_size, hidden_size, num_class).to(device)\n",
    "\n",
    "# CrossEntropyLoss and optimizer which minimize loss with learning rate step\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) \n",
    "\n",
    "train_error, test_error = train_model(model, my_train_input1, my_train_input2, my_train_classes1, my_train_classes2, train_target, criterion, optimizer, num_epochs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_error, 'r--', test_error, 'b--')\n",
    "plt.ylabel('some numbers')\n",
    "plt.title(\"Train error in red, test error in blue over the epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {}\".format(1-min(test_error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
